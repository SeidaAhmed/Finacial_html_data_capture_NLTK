{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeidaAhmed/Finacial_html_data_capture_NLTK/blob/main/PANW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "metadata": {
        "id": "ZLfvIE8EOF9p"
      },
      "outputs": [],
      "source": [
        "metrics_8k=[\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756725000006/ex991q225earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756724000036/ex991q125earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756724000023/ex991q424earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756724000015/ex991q324earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756724000003/ex991q224earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756723000030/ex991q124earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756723000020/ex991q423earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756723000012/ex991q323earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756723000005/ex991q223earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756722000035/ex991q123earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756722000020/ex991q422earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756722000014/ex991q322earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756722000006/ex991q222earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756721000037/ex991q122earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756721000020/ex991q421earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756721000012/ex991q321earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000162828021002659/ex991q221earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756720000037/ex991q121earningsrelea.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756720000025/ex991q420earningsrelea.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756720000015/ex991q320earningsrelea.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756720000002/ex991q220earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756719000036/ex991q120earningsrelea.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756719000023/ex991q419earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756719000014/ex991q319earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756719000006/ex991q219earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756718000029/ex991q119earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756718000018/ex991q418earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756718000011/ex991june1newsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756718000004/ex991q218earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756717000032/ex991q118earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756717000021/ex991q417earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756717000016/ex991q317earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756717000005/ex991q217earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756716000071/ex991q117earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756716000057/ex991q416earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756716000051/ex991q316earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756716000044/ex991q216earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756715000033/ex991q116earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756715000022/ex991q415earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756715000015/ex991q315earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756715000006/ex991q215earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756714000040/ex991q115earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756714000025/ex991q414earningsrelease.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000119312514215060/d734043dex991.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000119312514063754/d681045dex991.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000132756713000033/ex-991.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000119312513361421/d595340dex991.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000119312513241542/d546594dex991.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000119312513084193/d494278dex991.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000119312512493700/d449771dex991.htm\",\n",
        "\"https://www.sec.gov/Archives/edgar/data/1327567/000119312512386605/d408809dex991.htm\"\n",
        "]\n",
        "\n",
        "metrics_8k=['https://www.sec.gov/Archives/edgar/data/1327567/000132756723000005/ex991q223earningsrelease.htm']\n",
        "#Next-Generation Security ARR Growth\n",
        "#Next-Generation Security ARR $ value\n",
        "# billings growth %\n",
        "# billings growth $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coB_5a08PETP"
      },
      "source": [
        "Important imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 356,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBr5AhLKPJsL",
        "outputId": "0e74e7a1-fc9d-4fd0-dd1a-5656272e87eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Error loading path: Package 'path' not found in index\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "try:\n",
        "    import urllib.request as urllib3\n",
        "    #requests.packages.urllib3.contrib.pyopenssl.extract_from_urllib3()\n",
        "except ImportError:\n",
        "    import urllib3\n",
        "import zlib\n",
        "from nltk import Tree\n",
        "import re\n",
        "nltk.download('maxent_treebank_pos_tagger')\n",
        "nltk.download('path')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "years = []\n",
        "for i in range(2000,2100):\n",
        "  years.append(i)\n",
        "unit_conv={\"billion\":1000000000, \"million\":1000000,\"millions\":1000000,\"thousand\":1000,\"%\":0.01,\"percentage\":0.01,\"percent\":0.01,\"\":1,\"basis points\":0.0001,\"bps\":0.0001}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uL7mmtLP3I0"
      },
      "source": [
        "Functions that should generally stay the same:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 357,
      "metadata": {
        "id": "uXtUmNvJP6uI"
      },
      "outputs": [],
      "source": [
        "def extract_soup(url):\n",
        "\n",
        "    hdr = {'User-Agent': 'UbineerCorp info@ubineer.com','Accept-Encoding': 'gzip, deflate','host': 'www.sec.gov'}\n",
        "    s = requests.Session()\n",
        "    s.headers.update(hdr)\n",
        "    data = s.get(url)\n",
        "    s.close()\n",
        "    soup = BeautifulSoup(data.content, features=\"html.parser\")\n",
        "    return(soup)\n",
        "\n",
        "def openBS(html_file):\n",
        "\n",
        "  with open(html_file, encoding = \"ISO-8859-1\") as fp:\n",
        "\n",
        "    soup = BeautifulSoup(fp,'html.parser')\n",
        "\n",
        "  return soup\n",
        "\n",
        "def find_between( s, first, last ):\n",
        "    try:\n",
        "        start = s.index( first ) + len( first )\n",
        "        end = s.index( last, start )\n",
        "        return s[start:end]\n",
        "    except ValueError:\n",
        "        return \"\"\n",
        "\n",
        "def find_between_include(s, first, last, length):\n",
        "    try:\n",
        "        start = s.index( first ) - length\n",
        "        end = s.index( last, start )\n",
        "        return s[start:end]\n",
        "    except ValueError:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def unitConversion(insert_lst):\n",
        "  value = None\n",
        "  insert_lst[0] = insert_lst[0].replace('flat','0%')\n",
        "  unit_conv={\"billion\":1000000000,\"million\":1000000,\"thousand\":1000,\"%\":0.01,\"percentage\":0.01,\"percent\":0.01,\"\":1,\"basis points\":0.0001,\"bps\":0.0001}\n",
        "  if len(insert_lst) != 2:\n",
        "\n",
        "    for unit in list(unit_conv.keys()):\n",
        "      if unit == '':\n",
        "        pass\n",
        "      elif unit in insert_lst[0]:\n",
        "        insert_lst = [str(insert_lst[0]).replace(unit,''), unit]\n",
        "\n",
        "\n",
        "\n",
        "  insert_lst[-1] =insert_lst[-1].lower()\n",
        "\n",
        "\n",
        "  insert_lst[0] = str(insert_lst[0]).replace(',','').replace('$','').replace('(','-').replace(')','').replace('%','').strip()\n",
        "  #Andi adds brackets\n",
        "\n",
        "\n",
        "  insert_lst[0] = float(insert_lst[0])\n",
        "\n",
        "  for ele in unit_conv.keys():\n",
        "    #print(ele)\n",
        "    if ele == insert_lst[-1]:\n",
        "      value = insert_lst[0] * unit_conv[ele]\n",
        "      #attempt to fix floating point error\n",
        "      value = round(value,4)\n",
        "    else:\n",
        "      pass\n",
        "  if value == None:\n",
        "    print(\"Value is None: \", insert_lst)\n",
        "  return value\n",
        "\n",
        "def change_pos_tag(tag_sentence,model):\n",
        "    new_tag_lst=[]\n",
        "    for ele in tag_sentence:\n",
        "        if ele[0] in model.keys():\n",
        "            new_tag_lst.append((ele[0],model[ele[0]]))\n",
        "        else:\n",
        "            new_tag_lst.append(ele)\n",
        "    return(new_tag_lst)\n",
        "\n",
        "def listofdict (tree):\n",
        "  # source: https://stackoverflow.com/questions/63945863/converting-nltk-chunks-to-a-list-of-dictionaries\n",
        "  # need helper function to simply put chunks into dictionaries\n",
        "    dlist = []\n",
        "    d = {}\n",
        "    for item in tree:\n",
        "\n",
        "        if isinstance(item, Tree):\n",
        "\n",
        "            d[item.label()] = ' '.join([l[0] for l in item.leaves()])\n",
        "            dlist.append(d) if len(d)>0 else None\n",
        "            d = dict()\n",
        "\n",
        "    dlist.append(d) if len(d)>0 else None\n",
        "    return dlist\n",
        "\n",
        "def find_segment(listofdict):\n",
        "    # helper function\n",
        "    tl = \"Timeline\"\n",
        "    tl_count = 0\n",
        "    segment = 0\n",
        "    for i in range(len(listofdict)):\n",
        "        if tl in listofdict[i].keys():\n",
        "            tl_count +=1\n",
        "            if tl_count == 2:\n",
        "                segment = i\n",
        "                return segment\n",
        "    return len(listofdict)\n",
        "\n",
        "def combine_dict(listofdict):\n",
        "  # merge messy dictionaries from stack overflow function\n",
        "    master_outlook = []\n",
        "\n",
        "    while(len(listofdict) > 0 ):\n",
        "        segment = find_segment(listofdict)\n",
        "\n",
        "        time_dict = {}\n",
        "        for i in range(segment):\n",
        "            time_dict.update(listofdict[i])\n",
        "\n",
        "        listofdict = listofdict[segment:]\n",
        "        master_outlook.append(time_dict)\n",
        "    return master_outlook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYLDuNS4R5j7"
      },
      "source": [
        "Capture guidance function: This function captures all the text in the guidance section of the html file. It should generally stay the same unless the company has a weird format or you need to change out some specific words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mAk37vqSM-z",
        "outputId": "e872f245-babd-4e55-f6bd-f64c043da9a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "•Fiscal second quarter revenue and billings each grew 26% year over year to $1.7 billion and $2.0 billion, respectively•Trailing 12-months GAAP net income positive for period ending January 31, 2023•Remaining performance obligation grew 39% year over year to $8.8 billionSANTA CLARA, Calif., Feb. 21, 2023 — Palo Alto Networks (NASDAQ: PANW), the global cybersecurity leader, announced today financial results for its fiscal second quarter 2023, ended January 31, 2023.Total revenue for the fiscal second quarter 2023 grew 26% year over year to $1.7 billion, compared with total revenue of $1.3 billion for the fiscal second quarter 2022. GAAP net income for the fiscal second quarter 2023 was $84.2 million, or $0.25 per diluted share, compared with GAAP net loss of $93.5 million, or $0.32 per diluted share, for the fiscal second quarter 2022.Non-GAAP net income for the fiscal second quarter 2023 was $331.7 million, or $1.05 per diluted share, compared with non-GAAP net income of $185.0 million, or $0.58 per diluted share, for the fiscal second quarter 2022. A reconciliation between GAAP and non-GAAP information is contained in the tables below.\"We continue to see our teams execute well in the midst of macroeconomic challenges, helping customers consolidate their security architectures,\" said Nikesh Arora, chairman and CEO of Palo Alto Networks. \"The performance of our software-based and cloud-delivered portfolio validates the significant investments we have made over the last several years and has enabled us to raise our billings and NGS ARR guidance.\"\"Our focus on driving profitable growth is reflected in our Q2 results,\" said Dipak Golechha, chief financial officer of Palo Alto Networks. \"As a result, we are raising our cash flow margin and operating profitability targets as we remain focused on driving efficiency in our business.\"1\n",
            "•Fiscal second quarter revenue and billings each grew 26% year over year to $1.7 billion and $2.0 billion, respectively•Trailing 12-months GAAP net income positive for period ending January 31, 2023•Remaining performance obligation grew 39% year over year to $8.8 billionSANTA CLARA, Calif., Feb. 21, 2023 — Palo Alto Networks (NASDAQ: PANW), the global cybersecurity leader, announced today financial results for its fiscal second quarter 2023, ended January 31, 2023.Total revenue for the fiscal second quarter 2023 grew 26% year over year to $1.7 billion, compared with total revenue of $1.3 billion for the fiscal second quarter 2022. GAAP net income for the fiscal second quarter 2023 was $84.2 million, or $0.25 per diluted share, compared with GAAP net loss of $93.5 million, or $0.32 per diluted share, for the fiscal second quarter 2022.Non-GAAP net income for the fiscal second quarter 2023 was $331.7 million, or $1.05 per diluted share, compared with non-GAAP net income of $185.0 million, or $0.58 per diluted share, for the fiscal second quarter 2022. A reconciliation between GAAP and non-GAAP information is contained in the tables below.\"We continue to see our teams execute well in the midst of macroeconomic challenges, helping customers consolidate their security architectures,\" said Nikesh Arora, chairman and CEO of Palo Alto Networks. \"The performance of our software-based and cloud-delivered portfolio validates the significant investments we have made over the last several years and has enabled us to raise our billings and NGS ARR guidance.\"\"Our focus on driving profitable growth is reflected in our Q2 results,\" said Dipak Golechha, chief financial officer of Palo Alto Networks. \"As a result, we are raising our cash flow margin and operating profitability targets as we remain focused on driving efficiency in our business.\"1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fiscal second quarter revenue and billings each grew 26 %  year-over-year to $1.7  billion and $2.0  billion, respectively trailing 12-months gaap net income positive for period ending january 31, 2023 remaining performance obligation grew 39 %  year-over-year to $8.8  billionsanta clara, calif., feb. 21, 2023 — palo alto networks (nasdaq: panw), the global cybersecurity leader, announced today financial results for its fiscal second quarter 2023, ended january 31, 2023.total revenue for the fiscal second quarter 2023 grew 26 %  year-over-year to $1.7  billion, compared with total revenue of $1.3  billion for the fiscal second quarter 2022. gaap net income for the fiscal second quarter 2023 was $84.2  million, or $0.25  per diluted share, compared with gaap net loss of $93.5  million, or $0.32  per diluted share, for the fiscal second quarter 2022. non-gaap net income for the fiscal second quarter 2023 was $331.7  million, or $1.05  per diluted share, compared with non-gaap net income of $185.0  million, or $0.58  per diluted share, for the fiscal second quarter 2022. a reconciliation between gaap and non-gaap information is contained in the tables below.\"we continue to see our teams execute well in the midst of macroeconomic challenges, helping customers consolidate their security architectures,\" said nikesh arora, chairman and ceo of palo alto networks. \"the performance of our software-based and cloud-delivered portfolio validates the significant investments we have made over the last several years and has enabled us to raise our billings and ngs arr guidance.\"\"our focus on driving profitable growth is reflected in our q2 results,\" said dipak golechha, chief financial officer of palo alto networks. \"as a result, we are raising our cash flow margin and operating profitability targets as we remain focused on driving efficiency in our business.\"1']"
            ]
          },
          "metadata": {},
          "execution_count": 358
        }
      ],
      "source": [
        "def captureGuidance(eightK_lst):\n",
        "    guidance_bs4_lst=[]\n",
        "    for ele in eightK_lst:\n",
        "\n",
        "        bs4_8K=extract_soup(ele)\n",
        "        #print(bs4_8K.prettify())\n",
        "        test= bs4_8K.get_text()\n",
        "        #print(len(test))\n",
        "        result = find_between( test,\"Financial Results\" , \"Financial Outlook\")\n",
        "        print(result)\n",
        "        if not result: # some companies call outlook guidance\n",
        "          result = find_between( test, \"SANTA CLARA\", \"Conference Call Information\")\n",
        "        if not result: # pltr is inbetween outlook and earnings webcast\n",
        "          result = find_between( test, \"Financial Results\" , \"Analyst Meeting Information\")\n",
        "\n",
        "\n",
        "        #print(bs4_8K.select(test.name+':contains(\"Financial Outlook\")'))\n",
        "        print(result)\n",
        "        #print(bs4_8K.find(text=\"Quarterly Conference Call \").previous_element.parent)\n",
        "\n",
        "        result = re.sub(r'(\\d+)-(\\d+)', r'\\1 \\2', result)\n",
        "        result = re.sub(r'(\\$\\d+\\.\\d+)', r'\\1 ', result)\n",
        "        result = re.sub(r'\\b(low|mid|high|single|teens|to)-\\b', r'\\1 ', result)\n",
        "\n",
        "        replace = {'%':' % ','shares':' shares ','.For':' for','outstandingfull':' outstanding full ','20232exhibit':'2023 ','year over year':'year-over-year','millionfor':' million for ','\\n':' ',\n",
        "                '•': ' ','\\xa028':' ','\\xa017':' ','    ':'','◦':' ','million.':' million . ', '\\xa0':' ','%.': ' % .','\\uf0b7':' ','oRevenue':'revenue','oNon-GAAP':'non-gaap','●':' ','.Non-GAAP':'. non-gaap','.Revenues':'. revenues','breakeven':'$0'}\n",
        "        for word in replace:\n",
        "          result = result.replace(word,replace[word])\n",
        "        guidance_bs4_lst.append(result.strip().lower())\n",
        "    return guidance_bs4_lst\n",
        "\n",
        "metrics_data = captureGuidance(metrics_8k)\n",
        "metrics_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKO64TKAUZeW"
      },
      "source": [
        "These are the custom chunking model words. This will vary depending on the company, but the core words will stay in here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYwNsUJA6JlQ"
      },
      "source": [
        "Filter sentence function: Will need to change the stop words depending on the context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {
        "id": "t3C-uIY70-em"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = {'first': 'CD', 'second': 'CD', 'third': 'CD', 'fourth': 'CD', 'expected': 'expected', 'quarter': 'TIME', 'year': 'TIME', 'breakeven': 'CD', 'full':\n",
        "'CD', 'tax': 'tax', 'subscription': 'sub', 'billings': 'bill', 'billion': 'unit', 'revenue': 'rev', 'unit': 'unit', 'full-year': 'TIME', 'fiscal': 'TIME', 'million': 'unit',\n",
        "'share': 'share', 'shares': 'share', 'year-over-year': 'yoy', '%': '%', 'ebitda': 'ebitda', 'loss': 'loss', 'arr': 'arr', 'income': 'income', 'net': 'net', 'revenues': 'rev',\n",
        "'non-gaap': 'non-gaap', 'gaap': 'gaap', 'operating': 'op', 'margin': 'mar', 'services': 'ser', 'adjusted': 'adj', 'negative': 'negative', 'respectively': 'resp', 'basic': 'basic',\n",
        "'q1': 'TIME', 'q2': 'TIME', 'q3': 'TIME', 'q4': 'TIME', 'fy': 'TIME', 'expenses': 'expenses', 'quarter-over-quarter': 'qoq', 'expectation ': 'expect', 'gross': 'gross', 'growth': 'growth',\n",
        "'rate': 'rate', 'operations': 'op', 'operation': 'op', 'cash': 'cash', 'expenditures': 'expenses', 'provision': 'prov', 'thousand': 'unit', 'earning': 'earn', 'taxes': 'tax', 'expense': 'expenses',\n",
        "'interest': 'interest', 'subscriptions': 'sub', 'eps': 'eps', 'compensation': 'comp', 'amortization': 'amort', 'acquisition': 'acq', 'costs': 'cost', 'debt': 'debt', 'assumed': 'ass', 'common': 'com',\n",
        "'dec.': 'month', 'break-even': 'CD', 'free': 'free', 'flow': 'flow', 'annual': 'ann', 'cloud': 'cloud', 'positive': 'pos', 'zero': 'CD', 'comparable': 'comp', 'comp': 'comp', 'return': 'rtn', 'invested': 'inv',\n",
        "'capital': 'cap', 'dividend': 'div', 'payments': 'pay', 'target': 'target', 'consolidated': 'con','percent:%'\n",
        "'repurchases': 'repur', 'repurchase': 'repur','repurchased': 'repur', 'repayments': 'repay', 'maturities': 'matur', 'reduced': 'reduce', 'reducing': 'reduce', 'planned': 'plan', 'percent': '%', 'investments': 'inv',\n",
        "'profit': 'profit', 'low-teens': 'CD', 'fromsource': 'src', 'organic': 'organic', 'expansion': 'growth', 'bps': 'bps', 'increase': 'growth', 'half': 'CD', 'back': 'CD', 'ending': 'end', 'ended': 'end', 'count': 'count',\n",
        "'even': 'CD', 'single': '%', 'percentage': '%', 'low': 'CD', 'mid': 'CD', 'high': 'CD', 'flat': 'CD', 'teens': '%', 'margins': 'mar', 'core': 'core', 'non-u.s.': 'non-gaap', 'outlook': 'outlook', 'â€”': ':', 'homes': 'home',\n",
        "'closed': 'closed', 'end': 'end', 'lower': 'reduce', 'sg': 'sg', 'pre-tax': 'pre-tax', 'increasing': 'growth', 'financial': 'financial', 'roic': 'roic', 'basis': 'basis', 'points': 'points', 'sales': 'sales', 'period': 'period',\n",
        " 'double-digit': 'CD', 'saas': 'saas', 'license': 'license', 'attributable': 'att', 'stockholders':  'stkhdr', 'hardware': 'hardware', 'reduce': 'reduce', 'stock': 'stk', 'restoration': 'restoration', 'continuing': 'continuing',\n",
        " 'intangibles': 'intan', 'non-cash': 'non-cash', 'stock-based': 'stk', 'service': 'ser', 'expectations': 'expect', 'aggregates': 'aggr', 'freight-adjusted': 'frtadj', 'price': 'price',\n",
        "'digit': '%', 'asphalt': 'asphalt', 'concrete': 'concrete', 'calcium': 'calcium', 'sag': 'sag', 'depreciation': 'dpr', 'depletion': 'dpl', 'accretion': 'accr', 'shipment': 'spmt', 'cost': 'cost',\n",
        "'down': 'negative', 'up': 'pos', 'volume': 'vol', 'tons': 'tons', 'spending': 'spend', 'pricing': 'price', 'non-aggregates': 'non-aggr', 'improvement': 'growth', 'improve': 'growth', 'diluted': 'dil', 'earnings': 'earn',\n",
        "'foreign':'foreign','grew':'growth' , 'grow':'growth','grows': 'growth' ,'finance':'fin','currency':'currency','expect':'expect','marketable':'marketable','securities':'securities','headcount':'headcount', 'ARR' : 'ARR'}\n",
        "\n",
        "model.update({'january': 'month', 'february': 'month', 'march': 'month', 'april': 'month', 'may': 'month', 'june': 'month','july': 'month', 'august': 'month', 'september': 'month', 'october': 'month', 'november': 'month', 'december': 'month'})\n",
        "#meta specific\n",
        "model.update({'ad':'ad','dap':'dap','daus':'daus','map':'map','maus':'maus','impressions':'impr'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {
        "id": "zdLcu4Ft50id"
      },
      "outputs": [],
      "source": [
        "def filter_sent(sentence, model):\n",
        "    custom_stop = [\"approximately\",\"/\", ',','information','available',\"'s\",'follows',':','range','outstanding','respectively','average','basic','weighted-average','representing','weighted','ending','roughly','~','assuming', 'including', 'principal','payments','leases','projected']\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered_sentence = []\n",
        "    for w in sentence:\n",
        "        if (w not in stop_words and w not in custom_stop) or (w in model.keys()):\n",
        "            filtered_sentence.append(w)\n",
        "    return filtered_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SNzMoSe847Z"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY2XKUeNU9Fa"
      },
      "source": [
        "Chunking function: This is the most difficult function to write. Completely depends on the way the company writes their sentences. When writing this function it's best to print(tagged) to see what's being shown. During this stage changes may need to be made to the model and custom stop words, as well as the captureGuidance function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {
        "id": "qXMOa0ujVc66"
      },
      "outputs": [],
      "source": [
        "def metrics_CHUNK(sentence, model):\n",
        "\n",
        "    tagged_raw = nltk.pos_tag(sentence)\n",
        "\n",
        "    tagged = change_pos_tag(tagged_raw,model) #https://www.guru99.com/pos-tagging-chunking-nltk.html\n",
        "    print(tagged)\n",
        "\n",
        "    chunk_rev = r\"\"\"\n",
        "                 Timeline: {<TIME><CD><TIME><CD>}\n",
        "                 Bill_grow_Dollar: <TIME>?<CD>?<TIME><bill><growth><CD><\\%><yoy><\\$>{<CD>}<unit>\n",
        "                 Bill_Grow_Per: <TIME>?<CD>?<TIME><bill><growth>{<CD>}<\\%>\n",
        "                 Next_Gen_ARR_grow_Dollar:<arr><growth><CD><\\%><yoy><\\$>{<CD>}<unit>\n",
        "                 Next_Gen_ARR_grow_Per: <JJ><NN><arr><growth>{<CD>}<\\%>\n",
        "  \"\"\"\n",
        "    chunkParserrev = nltk.RegexpParser(chunk_rev)\n",
        "    chunkedrev = chunkParserrev.parse(tagged)\n",
        "\n",
        "\n",
        "    return listofdict(chunkedrev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JdvD40LVpuJ"
      },
      "source": [
        "Outlook function: I don't think this ever changes but I have only done one text company so far so I am including it here: This should end up giving a list of dictionaries that grouped together correctly. Make sure to check that the output is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLqjpDifXIDh",
        "outputId": "607ced8f-6ba7-48be-880b-d7fc83ccb5e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('fiscal', 'TIME'), ('second', 'CD'), ('quarter', 'TIME'), ('revenue', 'rev'), ('billings', 'bill'), ('grew', 'growth'), ('26', 'CD'), ('%', '%'), ('year-over-year', 'yoy'), ('$', '$'), ('1.7', 'CD'), ('billion', 'unit'), ('$', '$'), ('2.0', 'CD'), ('billion', 'unit'), ('respectively', 'resp'), ('trailing', 'VBG'), ('12-months', 'JJ'), ('gaap', 'gaap'), ('net', 'net'), ('income', 'income'), ('positive', 'pos'), ('period', 'period'), ('ending', 'end'), ('january', 'month'), ('31', 'CD'), ('2023', 'CD'), ('remaining', 'VBG'), ('performance', 'NN'), ('obligation', 'NN'), ('grew', 'growth'), ('39', 'CD'), ('%', '%'), ('year-over-year', 'yoy'), ('$', '$'), ('8.8', 'CD'), ('billionsanta', 'NN'), ('clara', 'NN'), ('calif.', 'VBP'), ('feb.', 'RB'), ('21', 'CD'), ('2023', 'CD'), ('—', 'NN'), ('palo', 'NN'), ('alto', 'NN'), ('networks', 'NNS'), ('(', '('), ('nasdaq', 'JJ'), ('panw', 'NN'), (')', ')'), ('global', 'JJ'), ('cybersecurity', 'NN'), ('leader', 'NN'), ('announced', 'VBD'), ('today', 'NN'), ('financial', 'financial'), ('results', 'NNS'), ('fiscal', 'TIME'), ('second', 'CD'), ('quarter', 'TIME'), ('2023', 'CD'), ('ended', 'end'), ('january', 'month'), ('31', 'CD'), ('2023.total', 'JJ'), ('revenue', 'rev'), ('fiscal', 'TIME'), ('second', 'CD'), ('quarter', 'TIME'), ('2023', 'CD'), ('grew', 'growth'), ('26', 'CD'), ('%', '%'), ('year-over-year', 'yoy'), ('$', '$'), ('1.7', 'CD'), ('billion', 'unit'), ('compared', 'VBN'), ('total', 'JJ'), ('revenue', 'rev'), ('$', '$'), ('1.3', 'CD'), ('billion', 'unit'), ('fiscal', 'TIME'), ('second', 'CD'), ('quarter', 'TIME'), ('2022.', 'CD'), ('gaap', 'gaap'), ('net', 'net'), ('income', 'income'), ('fiscal', 'TIME'), ('second', 'CD'), ('quarter', 'TIME'), ('2023', 'CD'), ('$', '$'), ('84.2', 'CD'), ('million', 'unit'), ('$', '$'), ('0.25', 'CD'), ('per', 'IN'), ('diluted', 'dil'), ('share', 'share'), ('compared', 'VBN'), ('gaap', 'gaap'), ('net', 'net'), ('loss', 'loss'), ('$', '$'), ('93.5', 'CD'), ('million', 'unit'), ('$', '$'), ('0.32', 'CD'), ('per', 'IN'), ('diluted', 'dil'), ('share', 'share'), ('fiscal', 'TIME'), ('second', 'CD'), ('quarter', 'TIME'), ('2022.', 'CD'), ('non-gaap', 'non-gaap'), ('net', 'net'), ('income', 'income'), ('fiscal', 'TIME'), ('second', 'CD'), ('quarter', 'TIME'), ('2023', 'CD'), ('$', '$'), ('331.7', 'CD'), ('million', 'unit'), ('$', '$'), ('1.05', 'CD'), ('per', 'IN'), ('diluted', 'dil'), ('share', 'share'), ('compared', 'VBN'), ('non-gaap', 'non-gaap'), ('net', 'net'), ('income', 'income'), ('$', '$'), ('185.0', 'CD'), ('million', 'unit'), ('$', '$'), ('0.58', 'CD'), ('per', 'IN'), ('diluted', 'dil'), ('share', 'share'), ('fiscal', 'TIME'), ('second', 'CD'), ('quarter', 'TIME'), ('2022.', 'CD'), ('reconciliation', 'NN'), ('gaap', 'gaap'), ('non-gaap', 'non-gaap'), ('contained', 'JJ'), ('tables', 'NNS'), ('.', '.'), ('``', '``'), ('continue', 'JJ'), ('see', 'VBP'), ('teams', 'NNS'), ('execute', 'VBP'), ('well', 'RB'), ('midst', 'RB'), ('macroeconomic', 'JJ'), ('challenges', 'NNS'), ('helping', 'VBG'), ('customers', 'NNS'), ('consolidate', 'VBP'), ('security', 'NN'), ('architectures', 'NNS'), (\"''\", \"''\"), ('said', 'VBD'), ('nikesh', 'JJ'), ('arora', 'NN'), ('chairman', 'NN'), ('ceo', 'NN'), ('palo', 'NN'), ('alto', 'NN'), ('networks', 'NNS'), ('.', '.'), ('``', '``'), ('performance', 'NN'), ('software-based', 'JJ'), ('cloud-delivered', 'JJ'), ('portfolio', 'NN'), ('validates', 'VBZ'), ('significant', 'JJ'), ('investments', 'inv'), ('made', 'VBN'), ('last', 'JJ'), ('several', 'JJ'), ('years', 'NNS'), ('enabled', 'VBD'), ('us', 'PRP'), ('raise', 'VB'), ('billings', 'bill'), ('ngs', 'NNS'), ('arr', 'arr'), ('guidance', 'NN'), ('.', '.'), ('``', '``'), ('``', '``'), ('focus', 'VB'), ('driving', 'VBG'), ('profitable', 'JJ'), ('growth', 'growth'), ('reflected', 'VBD'), ('q2', 'TIME'), ('results', 'NNS'), (\"''\", \"''\"), ('said', 'VBD'), ('dipak', 'NN'), ('golechha', 'NN'), ('chief', 'JJ'), ('financial', 'financial'), ('officer', 'NN'), ('palo', 'NN'), ('alto', 'NN'), ('networks', 'NNS'), ('.', '.'), ('``', '``'), ('result', 'NN'), ('raising', 'VBG'), ('cash', 'cash'), ('flow', 'flow'), ('margin', 'mar'), ('operating', 'op'), ('profitability', 'NN'), ('targets', 'NNS'), ('remain', 'VBP'), ('focused', 'JJ'), ('driving', 'JJ'), ('efficiency', 'NN'), ('business', 'NN'), ('.', '.'), ('``', '``'), ('1', 'CD')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Timeline': 'fiscal second quarter 2023'},\n",
              " {'Timeline': 'fiscal second quarter 2023'},\n",
              " {'Timeline': 'fiscal second quarter 2022.'},\n",
              " {'Timeline': 'fiscal second quarter 2023'},\n",
              " {'Timeline': 'fiscal second quarter 2022.'},\n",
              " {'Timeline': 'fiscal second quarter 2023'},\n",
              " {'Timeline': 'fiscal second quarter 2022.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 362
        }
      ],
      "source": [
        "\n",
        "def metrics_info(data):\n",
        "    Total_Outlook = []\n",
        "    for i in range(len(data)):\n",
        "        if data[i] != '':\n",
        "            list_dict_chunks = metrics_CHUNK(filter_sent(word_tokenize((data[i])),model),model)\n",
        "            Total_Outlook.extend(combine_dict(list_dict_chunks))\n",
        "\n",
        "    return Total_Outlook\n",
        "\n",
        "raw_info = metrics_info(metrics_data)\n",
        "raw_info\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMWaigutXgJl"
      },
      "source": [
        "Process function: Once all the data is in the correct dictionary, it needs to go through this process function to extract specifically the numbers. Uses the unitConversion function that's defined higher up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 363,
      "metadata": {
        "id": "R9-iYKOCYKXG"
      },
      "outputs": [],
      "source": [
        "def process(raw_info_dict): #If you ever find an error with this function let @Maxime know ASAP\n",
        "    temp_dict = {}\n",
        "    if \"Drop\" in raw_info_dict.keys():\n",
        "      raw_info_dict.pop(\"Drop\")\n",
        "\n",
        "    if len(raw_info_dict)>1:\n",
        "        temp_dict = {}\n",
        "        temp_dict[\"Timeline\"] = raw_info_dict[\"Timeline\"]\n",
        "\n",
        "        for key, value in raw_info_dict.items():\n",
        "          value = value.replace(\"low teens\", \"11 % 13 %\")\n",
        "          value = value.replace(\"high teens\",\"17 % 19 %\" )\n",
        "          value = value.replace(\"mid teens\", \"14 % 16 %\")\n",
        "          value = re.sub(r'(\\d+)-(\\d+)', r'\\1 \\2', value)#remove dash between two numbers\n",
        "          arr = value.split()\n",
        "          prefix = 1\n",
        "          vals = []\n",
        "          if (len(arr) == 0 or key==\"Timeline\"):\n",
        "            continue\n",
        "          conversions = [] #case where there are multiple conversions in the same captured data\n",
        "          conversion = ''\n",
        "          #Find unit conversion\n",
        "          for i, elem in enumerate(arr):\n",
        "            if elem == 'breakeven' or elem == 'break-even' or elem == 'zero': #replace words meaning 0\n",
        "              arr[i] = '0'\n",
        "            if elem in unit_conv.keys():\n",
        "              conversion = elem\n",
        "              conversions.append(conversion)\n",
        "          # Check if unit conversion is in key\n",
        "          if conversion == '':\n",
        "            for word in key.split():\n",
        "              if word.replace(\"(\",\"\").replace(\")\",\"\") in unit_conv.keys(): #Replace unit conversion in key, ie. if key is \"Revenue (in millions)\", it should be \"Revenue\"\n",
        "                conversion = word.replace(\"(\",\"\").replace(\")\",\"\")\n",
        "                conversions.append(conversion)\n",
        "\n",
        "          if len(conversions) == 0:\n",
        "            conversions.append('')\n",
        "\n",
        "          if len(set(conversions)) > 1:\n",
        "            multi = True\n",
        "          else:\n",
        "            multi = False\n",
        "\n",
        "          # regex finds () and [] brackets\n",
        "          key = re.sub(\"\\(.*?\\)|\\[.*?\\]\",\"\", key)\n",
        "          #Check if numbers should be negative\n",
        "          if (\"loss\" in arr) or (\"negative\" in arr) or (\"decrease\" in arr):\n",
        "            prefix = -1\n",
        "          conv_num = 0\n",
        "          #Find values (should be 1 or 2)\n",
        "\n",
        "\n",
        "          # IMPROVED HANDLING OF NEGATIVE AND POSITIVE VALS IN SAME CHUNK - by Jack Li\n",
        "          ignore_set = ['$']\n",
        "          switch = False\n",
        "          negative = False\n",
        "          state = 0\n",
        "          for elem in arr:\n",
        "            if \"(\" in elem and state == 0:\n",
        "              state = 1\n",
        "            if (elem.replace(\".\",\"\").replace(\",\",\"\").replace(\"$\",\"\").replace('(','').replace(')','').replace('%','').isdigit() and state == 1) or (elem == 'loss' and state == 1):\n",
        "              state = 2\n",
        "            if \")\" in elem and state == 1:\n",
        "              state = 0\n",
        "            if \")\" in elem and state == 2:\n",
        "              switch = True\n",
        "              break\n",
        "\n",
        "          pos_search = False\n",
        "\n",
        "          if switch is False:\n",
        "            for elem in arr:\n",
        "              if elem == 'positive':\n",
        "                pos_search = True\n",
        "                continue\n",
        "              if pos_search:\n",
        "                if (not elem.replace(\".\",\"\").replace(\",\",\"\").replace(\"$\",\"\").replace('(','').replace(')','').replace('%','').replace('-','').replace('~','').isdigit()) and (elem not in ignore_set):\n",
        "                  pos_search = False\n",
        "\n",
        "              if elem.replace(\".\",\"\").replace(\",\",\"\").replace(\"$\",\"\").replace('(','').replace(')','').replace('%','').replace('-','').replace('~','').isdigit():\n",
        "                if pos_search:\n",
        "                  vals.append(unitConversion([elem, conversions[conv_num]]))\n",
        "                  if multi: conv_num += 1\n",
        "                  pos_search = False\n",
        "                else:\n",
        "                  vals.append(unitConversion([elem, conversions[conv_num]])*prefix)\n",
        "                  if multi: conv_num += 1\n",
        "          else:\n",
        "            for elem in arr:\n",
        "              if \"(\" in elem:\n",
        "                negative = True\n",
        "              if \")\" in elem:\n",
        "                negative = False\n",
        "              if elem.replace(\".\",\"\").replace(\",\",\"\").replace(\"$\",\"\").replace('(','').replace(')','').replace('%','').replace('-','').replace('~','').isdigit():\n",
        "                if (negative):\n",
        "                  vals.append(unitConversion([elem, conversions[conv_num]])*-1)\n",
        "                  if multi: conv_num += 1\n",
        "                else:\n",
        "                  vals.append(unitConversion([elem, conversions[conv_num]]))\n",
        "                  if multi: conv_num += 1\n",
        "\n",
        "          if max(vals)-min(vals) > 100 * unit_conv[conversion]:\n",
        "            for val in vals:\n",
        "              if val/unit_conv[conversion] in years:\n",
        "                  vals.remove(val)\n",
        "                  break\n",
        "\n",
        "          temp_dict[key] = max(vals)\n",
        "          #temp_dict[key+\" Lower\"] = min(vals)\n",
        "\n",
        "    return temp_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcaAD-3fZlbM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7Cla6fCZhJ3",
        "outputId": "7de2b2ad-ffd0-421e-a322-12b5567daf80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 364
        }
      ],
      "source": [
        "def clean(raw_info):\n",
        "    Outlook = []\n",
        "    for i in range(len(raw_info)):\n",
        "        if process(raw_info[i]) != None:\n",
        "            Outlook.append(process(raw_info[i]))\n",
        "    return Outlook\n",
        "\n",
        "data = clean(raw_info)\n",
        "\n",
        "cleaned_data = [i for i in data if len(i)>1]\n",
        "cleaned_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {
        "id": "RuYcKJgyyDrm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_graphs(cleaned_data):\n",
        "  \"\"\"\n",
        "  Creates graphs based on the cleaned_data.\n",
        "  \"\"\"\n",
        "  for key in set().union(*[d.keys() for d in cleaned_data if 'Timeline' in d]):\n",
        "    if key != 'Timeline':\n",
        "      timelines = []\n",
        "      values = []\n",
        "\n",
        "      for d in cleaned_data:\n",
        "        if 'Timeline' in d and key in d:\n",
        "          timelines.append(d['Timeline'])\n",
        "          values.append(d[key])\n",
        "\n",
        "      if timelines and values:  # Check if there's data to plot\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(timelines, values, marker='o', linestyle='-')\n",
        "        plt.xlabel(\"Timeline\")\n",
        "        plt.ylabel(key)  # Use the key as the y-axis label\n",
        "        plt.title(f\"{key} over Time\")\n",
        "        plt.grid(True)\n",
        "        plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Assuming cleaned_data is defined as in the provided code\n",
        "create_graphs(cleaned_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {
        "id": "tvuZOSB-0zXT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}